{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Data cleaning\n",
    "###  Merge cleaned and timezone-corrected weather and meter data\n",
    "by: Alissa Stover, Sophia Skowronski, Ying Hua\n",
    "\n",
    "This Jupyter notebook merges the meter and weather data after they have been timezone-corrected and after the meter data has been cleaned.\n",
    "See discussion here for background on the timezone correction: https://www.kaggle.com/patrick0302/locate-cities-according-weather-temperature \n",
    "This code also derives from code found at this URL https://www.kaggle.com/caesarlupum/ashrae-ligthgbm-simple-fe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter data\n",
    "train_tz_df = pd.read_pickle('train_imputed_tz_df.pkl')\n",
    "test_tz_df = pd.read_pickle('test_imputed_tz_df.pkl')\n",
    "\n",
    "# Weather data\n",
    "weather_train_tz_df = pd.read_pickle('weather_train_tz_df.pkl')\n",
    "weather_test_tz_df = pd.read_pickle('weather_test_tz_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT: Commented out part below. Keep `timestamp_utc` column, which shows original weather timestamp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather df merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_tz_df[['site_id','timestamp', 'timezone', 'country_code', 'location']]\n",
    "temp_df = temp_df.merge(weather_train_tz_df, on=['site_id','timestamp', 'timezone', 'country_code', 'location'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp'], temp_df['timezone'], temp_df['country_code'], temp_df['location'], #, temp_df['timestamp_utc']\n",
    "\n",
    "train_tz_df = pd.concat([train_tz_df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>time_index</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>timezone_offset</th>\n",
       "      <th>timestamp_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>220.046471</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>101.917963</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5.634698</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>366.496399</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1568.406545</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>19.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  timestamp  meter_reading  site_id primary_use  \\\n",
       "0            0      0 2016-01-01     220.046471        0   Education   \n",
       "1            1      0 2016-01-01     101.917963        0   Education   \n",
       "2            2      0 2016-01-01       5.634698        0   Education   \n",
       "3            3      0 2016-01-01     366.496399        0   Education   \n",
       "4            4      0 2016-01-01    1568.406545        0   Education   \n",
       "\n",
       "   square_feet  year_built  floor_count  time_index  ...       timestamp_utc  \\\n",
       "0         7432      2008.0          8.0           0  ... 2016-01-01 05:00:00   \n",
       "1         2720      2004.0          5.0           0  ... 2016-01-01 05:00:00   \n",
       "2         5376      1991.0          4.0           0  ... 2016-01-01 05:00:00   \n",
       "3        23685      2002.0         10.0           0  ... 2016-01-01 05:00:00   \n",
       "4       116607      1975.0          1.0           0  ... 2016-01-01 05:00:00   \n",
       "\n",
       "   air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  \\\n",
       "0             19.4             NaN             19.4                0.0   \n",
       "1             19.4             NaN             19.4                0.0   \n",
       "2             19.4             NaN             19.4                0.0   \n",
       "3             19.4             NaN             19.4                0.0   \n",
       "4             19.4             NaN             19.4                0.0   \n",
       "\n",
       "   sea_level_pressure  wind_direction wind_speed timezone_offset  \\\n",
       "0                 NaN             0.0        0.0            -5.0   \n",
       "1                 NaN             0.0        0.0            -5.0   \n",
       "2                 NaN             0.0        0.0            -5.0   \n",
       "3                 NaN             0.0        0.0            -5.0   \n",
       "4                 NaN             0.0        0.0            -5.0   \n",
       "\n",
       "        timestamp_utc  \n",
       "0 2016-01-01 05:00:00  \n",
       "1 2016-01-01 05:00:00  \n",
       "2 2016-01-01 05:00:00  \n",
       "3 2016-01-01 05:00:00  \n",
       "4 2016-01-01 05:00:00  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = test_tz_df[['site_id','timestamp', 'timezone', 'country_code', 'location']]\n",
    "temp_df = temp_df.merge(weather_test_tz_df, on=['site_id','timestamp', 'timezone', 'country_code', 'location'], how='left')\n",
    "\n",
    "del temp_df['site_id'], temp_df['timestamp'], temp_df['timezone'], temp_df['country_code'], temp_df['location']#, temp_df['timestamp_utc']\n",
    "test_tz_df = pd.concat([test_tz_df, temp_df], axis=1)\n",
    "\n",
    "del temp_df, weather_train_tz_df, weather_test_tz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>...</th>\n",
       "      <th>dst</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>timezone_offset</th>\n",
       "      <th>timestamp_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  building_id  meter  timestamp  site_id primary_use  square_feet  \\\n",
       "0       0            0      0 2017-01-01        0   Education         7432   \n",
       "1       1            1      0 2017-01-01        0   Education         2720   \n",
       "2       2            2      0 2017-01-01        0   Education         5376   \n",
       "3       3            3      0 2017-01-01        0   Education        23685   \n",
       "4       4            4      0 2017-01-01        0   Education       116607   \n",
       "\n",
       "   year_built  floor_count  Unnamed: 0  ... dst air_temperature  \\\n",
       "0      2008.0          NaN           0  ...   0             NaN   \n",
       "1      2004.0          NaN           0  ...   0             NaN   \n",
       "2      1991.0          NaN           0  ...   0             NaN   \n",
       "3      2002.0          NaN           0  ...   0             NaN   \n",
       "4      1975.0          NaN           0  ...   0             NaN   \n",
       "\n",
       "  cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0            NaN              NaN                NaN                 NaN   \n",
       "1            NaN              NaN                NaN                 NaN   \n",
       "2            NaN              NaN                NaN                 NaN   \n",
       "3            NaN              NaN                NaN                 NaN   \n",
       "4            NaN              NaN                NaN                 NaN   \n",
       "\n",
       "   wind_direction  wind_speed  timezone_offset  timestamp_utc  \n",
       "0             NaN         NaN              NaN            NaT  \n",
       "1             NaN         NaN              NaN            NaT  \n",
       "2             NaN         NaN              NaN            NaT  \n",
       "3             NaN         NaN              NaN            NaT  \n",
       "4             NaN         NaN              NaN            NaT  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_tz_df[\"Unnamed: 0\"], test_tz_df[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'building_id', 'meter', 'timestamp', 'site_id', 'primary_use',\n",
       "       'square_feet', 'year_built', 'floor_count', 'timezone', 'country_code',\n",
       "       'location', 'timezone_offset', 'dst', 'air_temperature',\n",
       "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
       "       'sea_level_pressure', 'wind_direction', 'wind_speed', 'timezone_offset',\n",
       "       'timestamp_utc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tz_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'site_id',\n",
       "       'primary_use', 'square_feet', 'year_built', 'floor_count', 'time_index',\n",
       "       'day_of_week', 'hour_of_day', 'index', 'avg', 'std', 'outlier',\n",
       "       'timezone', 'country_code', 'location', 'timezone_offset', 'dst',\n",
       "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
       "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
       "       'wind_speed', 'timezone_offset', 'timestamp_utc', 'air_temperature',\n",
       "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
       "       'sea_level_pressure', 'wind_direction', 'wind_speed', 'timezone_offset',\n",
       "       'timestamp_utc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tz_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT: There are \"NaT\" values where the weather data is shifted and no longer matches test/training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT: Commenting out section since already in datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert timestamps to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'US/Central'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'US/Central'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'US/Mountain'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'US/Mountain'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'US/Pacific'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'US/Pacific'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'Canada/Eastern'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'Canada/Eastern'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'US/Eastern'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'US/Eastern'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'Europe/London'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'Europe/London'), 'timestamp'])\n",
    "#train_tz_df.loc[(train_tz_df['timezone'] == 'Europe/Dublin'), 'timestamp'] = pd.to_datetime(train_tz_df.loc[(train_tz_df['timezone'] == 'Europe/Dublin'), 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'US/Central'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'US/Central'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'US/Mountain'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'US/Mountain'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'US/Pacific'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'US/Pacific'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'Canada/Eastern'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'Canada/Eastern'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'US/Eastern'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'US/Eastern'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'Europe/London'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'Europe/London'), 'timestamp'])\n",
    "#test_tz_df.loc[(test_tz_df['timezone'] == 'Europe/Dublin'), 'timestamp'] = pd.to_datetime(test_tz_df.loc[(test_tz_df['timezone'] == 'Europe/Dublin'), 'timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Minification\n",
    "\n",
    "Save the final dataframes as pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tz_df.to_pickle('train_merge_df.pkl')\n",
    "test_tz_df.to_pickle('test_merge_df.pkl')\n",
    "   \n",
    "del train_tz_df, test_tz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the files\n",
    "To use these files, you must first read them in using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train_merge_df.pkl')\n",
    "test_df = pd.read_pickle('test_merge_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT: Summary of pickle file changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1: `train_df.pkl` \n",
    "`test_df.pkl`\n",
    "\n",
    "TO\n",
    "\n",
    "STEP 2: `train_df_imputed.pkl`\n",
    "`test_df_imputed.pkl`\n",
    "\n",
    "TO\n",
    "\n",
    "STEP 3: `train_imputed_tz_df.pkl`\n",
    "`test_imputed_tz_df.pkl`\n",
    "\n",
    "TO\n",
    "\n",
    "STEP 4: `train_merge_df.pkl`\n",
    "`test_merge_df.pkl`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
